
# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
path: /datasdc/zhouhuayi/dataset/AGORA/HPE/
labels: yolov5_labels_coco
train: yolov5_labels_coco/img_txt/train.txt
val: yolov5_labels_coco/img_txt/validation.txt

train_annotations: annotations/coco_style_train.json
val_annotations: annotations/coco_style_validation.json

nc: 1  # number of classes (only one class: human head)
num_angles: 3  # number of Euler angles is 3 (pitch, yaw, roll)
names: [ 'person' ]  # class names. We still use 'person' in json file

# nc: 18  # number of classes (person class + 17 keypoint classes)
# num_coords: 34  # number of keypoint coordinates (x, y)

# names: [ 'person', 'nose',  # class names
         # 'left_eye', 'right_eye',
         # 'left_ear', 'right_ear',
         # 'left_shoulder', 'right_shoulder',
         # 'left_elbow', 'right_elbow',
         # 'left_wrist', 'right_wrist',
         # 'left_hip', 'right_hip',
         # 'left_knee', 'right_knee',
         # 'left_ankle', 'right_ankle' ]

# kp_flip: [0, 2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15]  # for left-right keypoint flipping
# kp_left: [1, 3, 5, 7, 9, 11, 13, 15]  # left keypoints
# kp_face: [0, 1, 2, 3, 4]

